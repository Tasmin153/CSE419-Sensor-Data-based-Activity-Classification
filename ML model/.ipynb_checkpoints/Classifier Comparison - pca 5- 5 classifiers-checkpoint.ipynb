{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "h = .02  # step size in the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\",\"Decision Tree\", \"Random Forest\", \"Naive Bayes\", \"Neural Net\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-108-f5b0f29083cb>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-108-f5b0f29083cb>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    SVC(kernel=\"linear\", C=0.025),\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(alpha=1, max_iter=1000)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_finder(path):\n",
    "\n",
    "    file_list = []\n",
    "\n",
    "    for j in glob(path+\"*.csv\"):\n",
    "        file_list.append(j)\n",
    "\n",
    "    return file_list\n",
    "\n",
    "def read_file(path):\n",
    "\n",
    "    data = pd.read_csv(path, na_values = 'NaN', keep_default_na = False) \n",
    "    return data\n",
    "\n",
    "def pd_to_np(data):\n",
    "    \n",
    "    if type(data) == np.ndarray:\n",
    "      print('Data is already in numpy format!')\n",
    "    else:\n",
    "      data = data.values\n",
    "      #print('Pandas to Numpy done!')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def string_to_index(activity_label):\n",
    "\n",
    "    activity_class =[]\n",
    "    har_class = {\n",
    "                    'Cook':0,\n",
    "                    'Eat':1,\n",
    "                    'Phone':2,\n",
    "                    'Read':3,\n",
    "                    'Watch_TV':4\n",
    "                }\n",
    "    for label in activity_label:\n",
    "        activity_class.append(har_class[label[0]])\n",
    "\n",
    "    return activity_class\n",
    "\n",
    "\n",
    "def data_loader(path, split=0.3):\n",
    "    x = y = []\n",
    "    feature_list = []\n",
    "    \n",
    "    pd_data = read_file(path)\n",
    "\n",
    "    for i in pd_data:\n",
    "        feature_list.append(i)\n",
    "\n",
    "    selectData = pd_data.loc[:, feature_list[:-1]]\n",
    "    activityLabel = pd_data.loc[:, ['activity']]\n",
    "    x = pd_to_np(selectData)\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    y = string_to_index(activityLabel.values)\n",
    "    y = np.asarray(y) \n",
    "    y = y.astype('int32')\n",
    "    return x,y\n",
    "\n",
    "def full_dataset(file_list):\n",
    "\n",
    "    x=y = np.asarray([])\n",
    "    x_temp =  y_temp =  []\n",
    "\n",
    "    for i in range(len(file_list)):\n",
    "        x_temp, y_temp = data_loader(file_list[i])\n",
    "\n",
    "        if i == 0:\n",
    "            x = x_temp\n",
    "            y = y_temp\n",
    "        else:\n",
    "            x = np.concatenate([x, x_temp],axis=0)\n",
    "            y  = np.concatenate([y ,y_temp],axis=0)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = folder_finder(\"../Dataset/\")\n",
    "print(file_list)\n",
    "print('Total files:',len(file_list))\n",
    "X,y= full_dataset(file_list)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "\n",
    "dmap = {\n",
    "            0:'Cook',\n",
    "            1:'Eat',\n",
    "            2:'Phone',\n",
    "            3:'Read',\n",
    "            4:'Watch_TV'\n",
    "        }\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    X,y = data_loader(file_list[i])\n",
    "    pca = make_pipeline(StandardScaler(),PCA(n_components=5, random_state=42))\n",
    "    pc_train = pca.fit_transform(X)\n",
    "    print (\"shape of pca\",pc_train.shape)\n",
    "    ex_variance=np.var(pc_train,axis=0)\n",
    "    ex_variance_ratio = ex_variance/np.sum(ex_variance)\n",
    "    print (ex_variance_ratio) \n",
    "    print(\"\\nSum of ex_variance_ratio : \", np.sum(ex_variance_ratio)) \n",
    "#     pcaDf = pd.DataFrame(data = pc_train, columns = ['pc 1', 'pc 2','pc 3'])\n",
    "#     pcaDf['Target'] = y\n",
    "#     pcaDf['Target'] = pcaDf[\"Target\"].map(dmap)\n",
    "#     sns.FacetGrid(pcaDf,hue='Target',height=6).map(plt.scatter,'pc 1','pc 2','pc 3').add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure = plt.figure(figsize=(30, 30))\n",
    "\n",
    "# count = 1\n",
    "\n",
    "# for i in range(len(file_list)):\n",
    "#     X,y = data_loader(file_list[i])\n",
    "#     pca = PCA(n_components=3)\n",
    "#     pc_train = pca.fit_transform(X)\n",
    "#     pcaDf = pd.DataFrame(data = pc_train, columns = ['pc 1', 'pc 2','pc 3'])\n",
    "#     pcaDf['Target'] = y\n",
    "    \n",
    "#     ax = plt.subplot(6, 2, count)\n",
    "#     ax.scatter(X[:,0], y, color='r')\n",
    "#     ax.set_xlabel('X 0')\n",
    "#     ax.set_ylabel('y')\n",
    "#     ax.set_title('X vs y')\n",
    "    \n",
    "#     ax = plt.subplot(6, 2, count+1)\n",
    "#     ax.scatter(X[:,1], y, color='b')\n",
    "#     ax.set_xlabel('X 1')\n",
    "#     ax.set_ylabel('y')\n",
    "#     ax.set_title('X vs y')\n",
    "#     count+=2\n",
    "#     plt.savefig('{:03d}.png'.format(len(file_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pc_train\n",
    "print(X.shape)\n",
    "\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [linearly_separable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "#     # just plot the dataset first\n",
    "#     cm = plt.cm.RdBu\n",
    "#     cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "#     ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "#     if ds_cnt == 0:\n",
    "#         ax.set_title(\"Input data\")\n",
    "#     # Plot the training points\n",
    "#     ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,edgecolors='k')\n",
    "#     # Plot the testing points\n",
    "#     ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,edgecolors='k')\n",
    "#     ax.set_xlim(xx.min(), xx.max())\n",
    "#     ax.set_ylim(yy.min(), yy.max())\n",
    "#     ax.set_xticks(())\n",
    "#     ax.set_yticks(())\n",
    "#     i += 1\n",
    "\n",
    "    \n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "         ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "         clf.fit(X_train, y_train)\n",
    "         score = clf.score(X_test, y_test)\n",
    "         print (name,score)\n",
    "            \n",
    "\n",
    "\n",
    "#         # Plot the decision boundary. For that, we will assign a color to each\n",
    "#         # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "#          if hasattr(clf, \"decision_function\"):\n",
    "#              Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "#          else:\n",
    "#              Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "# #         # Put the result into a color plot\n",
    "#          Z = Z.reshape(xx.shape)\n",
    "#          #Z = Z.flatten().reshape(1960,420)\n",
    "#          ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "#          print(Z.shape)\n",
    "\n",
    "# #         # Plot the training points\n",
    "#          ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,edgecolors='k')\n",
    "# #         # Plot the testing points\n",
    "#          ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,edgecolors='k', alpha=0.6)\n",
    "\n",
    "#          ax.set_xlim(xx.min(), xx.max())\n",
    "#          ax.set_ylim(yy.min(), yy.max())\n",
    "#          ax.set_xticks(())\n",
    "#          ax.set_yticks(())\n",
    "#          if ds_cnt == 0:\n",
    "#              ax.set_title(name)\n",
    "#          ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "#                  size=15, horizontalalignment='right')\n",
    "#          i += 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def train_model(model, X_train, y_train):\n",
    "    return model.fit(X_train, y_train)\n",
    "\n",
    "def test_model(model,X_test):\n",
    "    pred = model.predict(X_test)\n",
    "    return pred\n",
    "    \n",
    "def model_init():\n",
    "\n",
    "    model = classifiers[0]\n",
    "    # model = DecisionTreeClassifier()\n",
    "    return model\n",
    "    \n",
    "def heatmap_cm(confusion_matrix):\n",
    "    sns.heatmap(confusion_matrix, annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion matrix', y=1.1)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# For model evolution\n",
    "def model_evalution(y_test, y_pred):\n",
    "    #confusion_matrix(y_test, y_pred)\n",
    "    print(\"------------------- Model evaluation ----------------\\n\\n\")\n",
    "    print(\"Confusion Matrix : \\n\",confusion_matrix(y_test, y_pred))\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Accuracy Score : \",accuracy_score(y_test,y_pred))\n",
    "    print(\"Classification Report : \\n\",classification_report(y_test, y_pred))\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"\")\n",
    "\n",
    "    heatmap_cm(pd.DataFrame(confusion_matrix(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_init()\n",
    "net = train_model(model,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = test_model(net,X_test)\n",
    "model_evalution(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, clf in zip(names, classifiers):\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     score = clf.score(X_test, y_test)\n",
    "#     print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
