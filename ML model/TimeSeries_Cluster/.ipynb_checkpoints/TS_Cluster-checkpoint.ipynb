{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from tensorflow.python.keras import backend as k\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_finder(path):\n",
    "\n",
    "    file_list = []\n",
    "\n",
    "    for j in glob(path+\"*.csv\"):\n",
    "        file_list.append(j)\n",
    "\n",
    "    return file_list\n",
    "\n",
    "def read_file(path):\n",
    "\n",
    "    data = pd.read_csv(path, na_values = 'NaN', keep_default_na = False) \n",
    "    return data\n",
    "\n",
    "def pd_to_np(data):\n",
    "    \n",
    "    if type(data) == np.ndarray:\n",
    "      print('Data is already in numpy format!')\n",
    "    else:\n",
    "      data = data.values\n",
    "      #print('Pandas to Numpy done!')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def string_to_index(activity_label):\n",
    "\n",
    "    activity_class =[]\n",
    "    har_class = {\n",
    "                    'Cook':0,\n",
    "                    'Eat':1,\n",
    "                    'Phone':2,\n",
    "                    'Read':3,\n",
    "                    'Watch_TV':4\n",
    "                }\n",
    "    for label in activity_label:\n",
    "        activity_class.append(har_class[label[0]])\n",
    "\n",
    "    return activity_class\n",
    "\n",
    "\n",
    "def data_loader(path, split=0.3):\n",
    "    x = y = []\n",
    "    feature_list = []\n",
    "    \n",
    "    pd_data = read_file(path)\n",
    "\n",
    "    for i in pd_data:\n",
    "        feature_list.append(i)\n",
    "\n",
    "    selectData = pd_data.loc[:, feature_list[:-1]]\n",
    "    activityLabel = pd_data.loc[:, ['activity']]\n",
    "    x = pd_to_np(selectData)\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    y = string_to_index(activityLabel.values)\n",
    "    y = np.asarray(y) \n",
    "    y = y.astype('int32')\n",
    "    return x,y\n",
    "\n",
    "def full_dataset(file_list):\n",
    "\n",
    "    x=y = np.asarray([])\n",
    "    x_temp =  y_temp =  []\n",
    "\n",
    "    for i in range(len(file_list)):\n",
    "        x_temp, y_temp = data_loader(file_list[i])\n",
    "\n",
    "        if i == 0:\n",
    "            x = x_temp\n",
    "            y = y_temp\n",
    "        else:\n",
    "            x = np.concatenate([x, x_temp],axis=0)\n",
    "            y  = np.concatenate([y ,y_temp],axis=0)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Dataset\\\\new_dataset.csv']\n",
      "Total files: 1\n",
      "(447530, 36)\n",
      "(447530,)\n"
     ]
    }
   ],
   "source": [
    "file_list = folder_finder(\"../Dataset/\")\n",
    "print(file_list)\n",
    "print('Total files:',len(file_list))\n",
    "X,y= full_dataset(file_list)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahbuba\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 447530, 36)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### EXaMPLE OF DATA FOR A SINGLE INDIVIDUAL ###\n",
    "data = np.array(X,dtype=np.float64)\n",
    "#data['Target'] = np.array(y, dtype=np.float64)\n",
    "### STANDARDIZE DATA ###\n",
    "\n",
    "def std(serie): return (serie - serie.mean(axis=0))/serie.std(axis=0)\n",
    "def reverse_std(serie): return serie.std(axis=0)+serie.mean(axis=0)\n",
    "\n",
    "reverse_data = np.array([data.std(axis=0)+data.mean(axis=0),data])\n",
    "data = np.array([(data-data.mean(axis=0))/data.std(axis=0),data])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIMENSIONALITY REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8271d0dcea2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_v2_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[1;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[0;32m    176\u001b[0m                              \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                              input_tensor=tensor)\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[0;32m     85\u001b[0m                                          \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                                          \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                                          name=self.name)\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(shape, ndim, dtype, sparse, name)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_placeholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "\n",
    "input_layer = Input(shape=data)\n",
    "encoder = TimeDistributed(Dense(200, activation='relu'))(input_layer)\n",
    "encoder = TimeDistributed(Dense(50, activation=\"relu\"))(encoder)\n",
    "\n",
    "decoder = TimeDistributed(Dense(50, activation='relu'))(encoder)\n",
    "decoder = TimeDistributed(Dense(200, activation='relu'))(decoder)\n",
    "\n",
    "out = TimeDistributed(Dense(3))(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=out)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(data[:10],data[:10], epochs=100, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRY TO RECONSTRUCT ERRORS ###\n",
    "\n",
    "predictions = autoencoder.predict(data[11][np.newaxis,:,:]) * reverse_data[11]\n",
    "\n",
    "mse = np.mean(np.power(data[11] - predictions[0], 2), axis=1)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.scatter(y=mse,x=range(data.shape[1]))\n",
    "plt.title('reconstruction error '+person_id[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructe_error(series, reverse_data):\n",
    "    \n",
    "    predictions = autoencoder.predict(series[np.newaxis,:,:]) * reverse_data\n",
    "    mse = np.mean(np.power(series - predictions[0], 2), axis=1)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELATION CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPUTE CORRELATION MATRIX ###\n",
    "\n",
    "df = pd.DataFrame([reconstructe_error(series,reverse) for series,reverse in zip(data[10:],reverse_data[10:])]).T\n",
    "print(df.shape)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(df.corr())\n",
    "plt.xticks(range(len(person_id[10:])), person_id[10:])\n",
    "plt.yticks(range(len(person_id[10:])), person_id[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HIERACHICAL CLUSTERING ###\n",
    "\n",
    "X = df.corr().values\n",
    "d = sch.distance.pdist(X)\n",
    "L = sch.linkage(d, method='ward')\n",
    "ind = sch.fcluster(L, d.max()*0.99, 'distance')\n",
    "columns = [df.columns.tolist()[i] for i in list((np.argsort(ind)))]\n",
    "df = df.reindex(columns, axis=1)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(df.corr())\n",
    "plt.xticks(range(len(person_id[10:])), person_id[10:])\n",
    "plt.yticks(range(len(person_id[10:])), person_id[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT DENDROGRAM ###\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "dendrogram = sch.dendrogram(L, labels=person_id[10:])\n",
    "plt.hlines(d.max()*0.99,0,np.max(dendrogram['icoord']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KOLMOGOROV SMIRNOV CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPUTE KOLMOGOROV SMIRNOV MATRIX ###\n",
    "\n",
    "df = pd.DataFrame([reconstructe_error(series,reverse) for series,reverse in zip(data[10:],reverse_data[10:])]).T\n",
    "print(df.shape)\n",
    "\n",
    "results = []\n",
    "for i in range(len(df.columns)):\n",
    "    kf_test = df.apply(lambda x: stats.ks_2samp(df.iloc[:,i].values, x)[0],axis=0)\n",
    "    results.append(kf_test.tolist())\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(results)\n",
    "plt.xticks(range(len(person_id[10:])), person_id[10:])\n",
    "plt.yticks(range(len(person_id[10:])), person_id[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HIERACHICAL CLUSTERING ###\n",
    "\n",
    "X = np.asarray(results)\n",
    "d = sch.distance.pdist(X)\n",
    "L = sch.linkage(d, method='ward')\n",
    "ind = sch.fcluster(L, d.max()*0.99, 'distance')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(X[:,np.argsort(ind)])\n",
    "plt.xticks(range(len(person_id[10:])), person_id[10:])\n",
    "plt.yticks(range(len(person_id[10:])), person_id[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT DENDROGRAM ###\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "dendrogram = sch.dendrogram(L, labels=person_id[10:])\n",
    "plt.hlines(d.max()*0.95,0,np.max(dendrogram['icoord']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
